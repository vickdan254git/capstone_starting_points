{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(r'..\\capstones\\ai-tech-capstone\\cohort-3\\data\\train.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Ind] Instantiate a standard scaler to scale each feature in the data to a standard normal distribution. This is essential in regularized logistic regressions because they are not scale invariant. If we do not do this, then features with larger values will be more heavily penalized by the regularization term."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. [Ind] Instantiate a new SMOTE object."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. [Ind] Instantiate a logistic regression object like in the previous week, but this time assign it an L2 penalty."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. [Grp] Combine the scaler, SMOTE, and logistic regression objects into a pipeline. Explain why we need to do this rather than scaling and resampling all of the training data before our cross-validation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. [Ind] Run a grid search cross-validation to evaluate different hyperparameter choices for C in the logistic regression, where C is the multiplicative inverse of the   parameter we discussed earlier. You will need to decide what values of C to try, the number of folds k, and the scoring metric. We recommend talking to your group mentor about considerations for these choices."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Evaluate Cross-Validation Results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Ind] Write a function that takes the GridSearchCV.cv results from your grid search as an argument."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. [Ind] In the function, plot the mean score as a function of C."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. [Ind] Now have the function return the value for C that achieves the maximum score. If there are ties, choose the C with the smallest value (most regularized)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# At this point, you have enough information to pick a good hyperparameter; however, you have only used the mean of the score without incorporating the variance of the score across the folds. Over the next few steps, you will incorporate the variance of the cross-validation results to apply a common heuristic in logistic regression called the one standard error rule."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Ind] In the same function as before, calculate the standard error of the mean score by dividing the standard error of the scores by the square root of the number of folds."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. [Ind] In the plot, add error bars that show the standard error of the mean scores."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. [Ind] In the function, in addition to the C that corresponds to the best mean score, return the smallest C that is within one standard error of the optimal C. This choice of C gets you a model that is more regularized than the model with the best mean score but at a statistically similar performance. This is a heuristic called the one standard error rule that chooses to have a simpler model at the cost of slightly worse performance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. [Ind] In the plot, add a band that shows the region for the one standard error rule (see Figure 2.1). Pyplot’s fill between may be useful."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. [Ind] Add the resulting plot to your document and write a few sentences interpreting the plot. You might want to think about how regularization relates to performance and which C you would choose (one standard-error vs maximum)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Inference on the Test Set"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Grp] Pick which C you want to use from your grid search. This should be one of the two values that you return from the function you wrote."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. [Grp] Fit the model to all the training data with your chosen C and do not forget to scale the data! Explain why you should fit your model to all the training data at this step."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. [Grp] Report the performance of the model on the validation data using the function you wrote previously."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. [Grp] Now use the model to predict the labels on the test data and submit the results to your group mentor. Make sure to keep the original order of the test data in your submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
